{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x,train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, variance=1.0): return (torch.randn(size)*variance).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets): \n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb): return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonLinear(xb):\n",
    "    res = xb@weights+bias\n",
    "    res = res.max(tensor(0.0))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward() #calculates gradient and adds to existing gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train epoch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl: \n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr #tells Pytorch not to update the gradients using that calculation\n",
    "            p.grad.zero_() #reset the gradients, _ is an inplace modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(preds,yb):\n",
    "    preds = preds.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb),yb) for xb, yb in valid_dl] #note: model(xb) = preds\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model and check validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7545 0.8806 0.9162 0.9352 0.9435 0.9499 0.9543 0.9548 0.9577 0.9592 0.9611 0.9621 0.9626 0.9636 0.9656 0.9656 0.9675 0.968 0.968 0.968 "
     ]
    }
   ],
   "source": [
    "params = weights, bias\n",
    "epoch_num = 20\n",
    "lr = 1.\n",
    "for i in range(epoch_num):\n",
    "    train_epoch(nonLinear, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Easier version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.329335</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>0.507851</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.152631</td>\n",
       "      <td>0.238785</td>\n",
       "      <td>0.793425</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.084361</td>\n",
       "      <td>0.120057</td>\n",
       "      <td>0.911678</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.055242</td>\n",
       "      <td>0.080848</td>\n",
       "      <td>0.938175</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>0.062945</td>\n",
       "      <td>0.953876</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034890</td>\n",
       "      <td>0.052877</td>\n",
       "      <td>0.962709</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.046533</td>\n",
       "      <td>0.964181</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.028373</td>\n",
       "      <td>0.042204</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>0.039069</td>\n",
       "      <td>0.968597</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.025072</td>\n",
       "      <td>0.036680</td>\n",
       "      <td>0.969087</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023899</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022919</td>\n",
       "      <td>0.033246</td>\n",
       "      <td>0.971541</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.022084</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.030845</td>\n",
       "      <td>0.973503</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020731</td>\n",
       "      <td>0.029878</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.020173</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>0.974975</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>0.028258</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.027571</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.026947</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018448</td>\n",
       "      <td>0.026380</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017793</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.024949</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.017232</td>\n",
       "      <td>0.024545</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016520</td>\n",
       "      <td>0.023502</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.023202</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.022922</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015744</td>\n",
       "      <td>0.022416</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015573</td>\n",
       "      <td>0.022187</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.021772</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.021582</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014965</td>\n",
       "      <td>0.021404</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>0.021236</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014697</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.020786</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffdb366bd90>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2)) #TODO: Find optimum learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98233562707901"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = learn.recorder.values[-1][2]; accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
